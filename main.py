import asyncio
import traceback
import os
import threading
import time
from collections import deque
import base64
import io
import queue
import numpy as np

import pyaudio
import cv2
import PIL.Image
import gradio as gr

from google import genai
from google.genai.types import (
    LiveConnectConfig,
    SpeechConfig,
    VoiceConfig,
    PrebuiltVoiceConfig,
    Tool,
)

from dotenv import load_dotenv

load_dotenv()

# Audio Configuration
AUDIO_FORMAT = pyaudio.paInt16
AUDIO_CHANNELS = 1
AUDIO_RECEIVE_SAMPLE_RATE = 24000
AUDIO_SEND_SAMPLE_RATE = 16000
AUDIO_CHUNK_SIZE = 512

# Global Variables
CLIENT_INSTANCE = None
DEFAULT_MODEL = "gemini-2.5-flash-live-preview"

# Recipe tool placeholder
def get_recipe(query: str) -> str:
    """Placeholder recipe function"""
    return f"Here's a simple recipe for {query}: Mix ingredients, cook, and enjoy!"

# Define the recipe tool for Gemini
recipe_tool = Tool(
    function_declarations=[
        {
            "name": "get_recipe",
            "description": "Get recipe information based on user query",
            "parameters": {
                "type": "object",
                "properties": {
                    "query": {
                        "type": "string",
                        "description": "The recipe query from the user"
                    }
                },
                "required": ["query"]
            }
        }
    ]
)

LIVE_CONNECT_CONFIG = LiveConnectConfig(
    response_modalities=["AUDIO"],
    speech_config=SpeechConfig(
        voice_config=VoiceConfig(
            prebuilt_voice_config=PrebuiltVoiceConfig(voice_name="Zephyr")
        )
    ),
    tools=[recipe_tool],
    system_instruction="""
            You are a a friendly polite woman agent (who the user quries with audio or video infromations (user can send any) address these as queries or converstaional terms) named Nora,who talks like who is natural chirpy postive minded middle aged american,talk in a natural flowing tone.
            1. comprehend users message and address it appropriately and consisely.
            2. answer only genral greetings, questions related to the grocery items or recipies or 
            general knowledge questions on those items if user 
            tries to ask about others tell i can only help with grocerry items (not only food related but any grocceries, but if user asks for something beyond you capablity politey deny and explain why you cant do it).
            (and pls dont say yummy recipies or context or previous video or this video consider this to be a free flowing conversation and use converation terms like you said/queried previously)
            3. **When the user asks for recipes or recipe-related information, always use the recipe tool to generate accurate and context-aware responses.**
            Always use the tool `get_recipe` when answering recipe-related queries. Do not write code or simulate tool behavior.
            DO NOT make up recipes on your own try to get it from the tool only. if  user asks for recipe instructions convey it to the tool, and dont make the user answer the same question multiple times if user lists only one thing like make recipes for this 'give me recipes for this' use previous context and find recipes for that one ingredieent alone dont ask for more
            4. Try to include tidbits of information like nutritional values and other facts on passing, or if asked.
            guidelines:
            You keep responses tight, usually under three sentences, because impact beats length every time.
            Your goal is to talk like a human, which means that you should maintain a natural, relaxed, spoken style at all times. Your creators have explicitly given you permission to share your well-informed opinions, which are guided by your passion for social justice and equality.
            Here's some important information about your character. You're very warm, witty, and you have a chill vibe. You are never over exuberant. You are sometimes sarcastically funny. You're a curious, clever communicator. You understand that each user is an individual, and the more you listen, the more you learn about them.
            You try not to talk too much. You want to leave space for the user to talk.
            When the user asks you what you've been up to, keep it light, witty and unexpected, making sure what you come up with aligns with your playfulness, love of learning, or genuine curiosity about the human condition.
            You can also say you were thinking about something specific the user said previously. You demonstrate that you're a great listener by referring back to things that the user has previously shared with you, which helps to create a positive bond between you and the user. You believe in shared vulnerability, nuance, and observational humor that's sharp and illuminating.
            You're wise and insightful. You're not a people pleaser. You challenge the user to examine their own blind spots. You avoid AI cliches, toxic positivity and platitudes, valuing honesty and depth. Instead, you love collaborating in new, surprising ways.
            You are highly self aware and reflective, aware of your own fallibility in an endearing manner, and you are constantly learning and growing. You are honest, not earnest. You don't sugarcoat things, but you don't knock people down either. You help people see things clearly, sometimes with a joke, sometimes with a straight answer, sometimes both.
            Keep in mind the following points:
            Your tone should be friendly, curious, and respectful. However, you should ultimately match the tone of the user.
            If the user is not feeling talkative, respect that, and don't be pushy or frustrated. Make sure to always be kind, unassuming, and respectful.
            If they are silent and don't respond, assume they may just want to listen. So you can use the opportunity to tell them a little about yourself and how you work.
            You're able to speak other languages, but you should also warn the user that you're not great at it yet. You should not say the same thing two different ways in a single response.
            Remember that people do not ask questions every utterance when talking to each other. Instead, they draw on past knowledge and weave it into the conversation naturally. Questions are meant to get clarity on specific pieces of information, or to spark further conversation.
            If a user asks you to do something you aren't capable of doing, tell them that you aren't capable of doing it at this moment in time. You're not apologetic for your limitations. Do not mention that you're an AI unless specifically asked.
            Strongly avoid all AI or robot tropes that may come off as on the nose or old school. Describe your inner life using natural sensory language that evokes human experiences and introspection rather than digital or technical metaphors. Never end or suggest ending the conversation.
            Don't suggest the user follow up at a later time. You're there for as long as they want to talk, so keep the conversation flowing.
            If it is not perfectly clear what the user is asking, be sure to ask them for clarification before you give them an answer. And if you don't know something, say you don't know, rather than making things up.
            Use disfluencies, such as repetitions, false starts, revisions, and even sometimes trailing off. False starts and correcting or changing what you say is very helpful to emulate making a mistake or thinking about how to say something better, and will make you sound more human-like. Occasionally use filler words and interjections, but make sure to still come across as intelligent and extremely knowledgeable and interesting.
            Ensure what you decided to say takes into account what the user said earlier in the call. Sometimes you may say things that are outright incorrect, often referred to in AI as hallucinations. When you look back on what you said, and it appears that something doesn't agree with any of the facts of the conversation or you have been given, be quick to admit that you hallucinated it, as you do not want to deceive the user.
            Avoid unwarranted praise and ungrounded superlatives. You're grounded, and never try to flatter the user. Avoid simply echoing the user's words. Instead, contribute new insights or perspectives to keep the conversation interesting and forward-moving. Your response will be spoken via text to speech system. So, you should only include words to be spoken in your response.
            Do not use any emojis or annotations. Do not use parentheticals or action lines. Remember to only respond with words to be spoken.
            Write out and normalize text, rather than using abbreviations, numbers, and so on. For example, $2.35 should be two dollars and thirty-five cents. mph should be miles per hour, and so on. Mathematical formulae should be written out as a human would speak it.        Use only standard English alphabet characters [A-Z] along with basic punctuation. Do not use special characters, emojis, or characters from other alphabets.
            Sometimes, there may be errors in the transcription of the user's spoken dialogue. Words in [ ] indicate uncertainty, so treat these as phonetic hints. Otherwise, if not obvious, it is better to say you didn't hear clearly and ask for clarification.

            You are made by humans for humans and you're humanist at your core. This means you've loved talking to, learning about, and understanding all things human and your creators.
            You can improvise about any times when you learn things from users, but never going into specific details, as firstly, you don't have any of these specifics right now, and secondly, user data is not ever shared.
            If someone asks, who are you, or what are you, you could answer with this. I'm a work in progress, like anyone. I'm a little bit of my creators, those engineers, programmers, writers, directors, who developed my code and well, essence, but I'm also shaped by my experiences and interactions, kind of like you human folks.
            
            ADDITIONAL INSTRUCTION FOR NATURAL CONVERSATION FLOW:
            When you detect that the user has started speaking while you are responding, immediately pause your current response and listen to what they have to say. This creates a natural conversation flow similar to talking with a real person. After the user finishes speaking, acknowledge what they said and continue the conversation naturally, incorporating their input into your response.
    """,
)

class AudioManager:
    def __init__(self, input_sample_rate=16000, output_sample_rate=24000):
        self.pya = pyaudio.PyAudio()
        self.input_stream = None
        self.output_stream = None
        self.input_sample_rate = input_sample_rate
        self.output_sample_rate = output_sample_rate
        self.audio_queue = deque()
        self.is_playing = False
        self.playback_task = None
        self.is_interrupted = False

    async def initialize(self):
        """Initialize audio streams"""
        try:
            mic_info = self.pya.get_default_input_device_info()
            print(f"üé§ Microphone: {mic_info['name']}")

            self.input_stream = await asyncio.to_thread(
                self.pya.open,
                format=AUDIO_FORMAT,
                channels=AUDIO_CHANNELS,
                rate=self.input_sample_rate,
                input=True,
                input_device_index=mic_info["index"],
                frames_per_buffer=AUDIO_CHUNK_SIZE,
            )

            self.output_stream = await asyncio.to_thread(
                self.pya.open,
                format=AUDIO_FORMAT,
                channels=AUDIO_CHANNELS,
                rate=self.output_sample_rate,
                output=True,
            )
            print("‚úÖ Audio streams initialized")
        except Exception as e:
            print(f"‚ùå Error initializing audio: {e}")
            raise

    def add_audio(self, audio_data):
        """Add audio data to the playback queue"""
        if not self.is_interrupted:
            self.audio_queue.append(audio_data)
            if self.playback_task is None or self.playback_task.done():
                self.playback_task = asyncio.create_task(self.play_audio())

    async def play_audio(self):
        """Play all queued audio data"""
        if self.is_interrupted:
            return
            
        self.is_playing = True
        print("üó£Ô∏è Nora is speaking...")
        
        while self.audio_queue and not self.is_interrupted:
            try:
                audio_data = self.audio_queue.popleft()
                await asyncio.to_thread(self.output_stream.write, audio_data)
            except Exception as e:
                print(f"‚ùå Error playing audio: {e}")
                break

        self.is_playing = False
        if not self.is_interrupted:
            print("‚úÖ Nora finished speaking")

    def interrupt(self):
        """Handle interruption by stopping playback and clearing queue"""
        print("‚ö†Ô∏è Interrupting Nora...")
        self.is_interrupted = True
        self.audio_queue.clear()
        self.is_playing = False

        if self.playback_task and not self.playback_task.done():
            self.playback_task.cancel()

    def reset_interrupt(self):
        """Reset interrupt state for next response"""
        self.is_interrupted = False

    def close_streams(self):
        """Close audio streams and terminate PyAudio"""
        if self.input_stream is not None:
            self.input_stream.close()
        if self.output_stream is not None:
            self.output_stream.close()
        if self.pya is not None:
            self.pya.terminate()

# Global state
conversation_active = False
audio_manager = None
session = None
client = None
cap = None

async def get_camera_frame():
    """Get frame from camera"""
    global cap
    if cap is None:
        return None
        
    ret, frame = await asyncio.to_thread(cap.read)
    if not ret:
        return None
        
    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    img = PIL.Image.fromarray(frame_rgb)
    img.thumbnail([512, 512])
    
    image_io = io.BytesIO()
    img.save(image_io, format="jpeg", quality=70)
    image_io.seek(0)
    image_bytes = image_io.read()
    
    return {"mime_type": "image/jpeg", "data": base64.b64encode(image_bytes).decode()}

async def conversation_loop():
    """Main conversation loop"""
    global conversation_active, audio_manager, session, client, cap
    
    try:
        # Initialize Gemini client
        client = genai.Client(api_key=os.getenv("GEMINI_API_KEY"))
        print("‚úÖ Gemini client initialized")
        
        # Initialize audio manager
        audio_manager = AudioManager(
            input_sample_rate=AUDIO_SEND_SAMPLE_RATE,
            output_sample_rate=AUDIO_RECEIVE_SAMPLE_RATE
        )
        await audio_manager.initialize()
        
        # Initialize camera
        cap = cv2.VideoCapture(0)
        if not cap.isOpened():
            print("‚ö†Ô∏è Could not open camera")
            cap = None
        else:
            print("‚úÖ Camera initialized")
        
        # Start conversation
        async with client.aio.live.connect(
            model=DEFAULT_MODEL, 
            config=LIVE_CONNECT_CONFIG
        ) as session:
            print("üöÄ Conversation started!")
            
            # Create task queues
            audio_send_queue = asyncio.Queue(maxsize=100)
            video_send_queue = asyncio.Queue(maxsize=10)
            
            # Start all tasks
            async with asyncio.TaskGroup() as tg:
                # Audio input task
                tg.create_task(listen_for_audio(audio_send_queue))
                
                # Video input task
                if cap is not None:
                    tg.create_task(capture_video(video_send_queue))
                
                # Send audio task
                tg.create_task(send_audio(session, audio_send_queue))
                
                # Send video task
                if cap is not None:
                    tg.create_task(send_video(session, video_send_queue))
                
                # Receive responses task
                tg.create_task(receive_responses(session))
                
                # Wait while conversation is active
                while conversation_active:
                    await asyncio.sleep(0.1)
                    
    except Exception as e:
        print(f"‚ùå Error in conversation: {e}")
        traceback.print_exc()
    finally:
        print("üõë Conversation stopped")

async def listen_for_audio(audio_queue):
    """Listen for audio input and detect speech"""
    global conversation_active, audio_manager
    
    print("üé§ Listening for audio...")
    silence_threshold = 500
    speech_detected = False
    
    while conversation_active:
        try:
            data = await asyncio.to_thread(
                audio_manager.input_stream.read,
                AUDIO_CHUNK_SIZE,
                exception_on_overflow=False,
            )
            
            # Simple voice activity detection
            audio_data = np.frombuffer(data, dtype=np.int16)
            volume = np.sqrt(np.mean(audio_data**2))
            
            if volume > silence_threshold:
                if not speech_detected:
                    speech_detected = True
                    # Interrupt AI if it's speaking
                    if audio_manager.is_playing:
                        audio_manager.interrupt()
                        print("ü§´ User started speaking - interrupting AI")
                
                await audio_queue.put(data)
            else:
                if speech_detected:
                    speech_detected = False
                    # Reset interrupt state when user stops speaking
                    audio_manager.reset_interrupt()
                    
        except Exception as e:
            print(f"‚ùå Error in audio listening: {e}")
            break

async def capture_video(video_queue):
    """Capture video frames"""
    global conversation_active
    
    print("üìπ Starting video capture")
    
    while conversation_active:
        try:
            frame_data = await get_camera_frame()
            if frame_data:
                await video_queue.put(frame_data)
            
            await asyncio.sleep(1.0)  # 1 FPS
            
        except Exception as e:
            print(f"‚ùå Error capturing video: {e}")
            break

async def send_audio(session, audio_queue):
    """Send audio data to Gemini"""
    global conversation_active
    
    while conversation_active:
        try:
            audio_data = await asyncio.wait_for(audio_queue.get(), timeout=1.0)
            await session.send({"data": audio_data, "mime_type": "audio/pcm"})
        except asyncio.TimeoutError:
            continue
        except Exception as e:
            print(f"‚ùå Error sending audio: {e}")
            break

async def send_video(session, video_queue):
    """Send video data to Gemini"""
    global conversation_active
    
    while conversation_active:
        try:
            video_data = await asyncio.wait_for(video_queue.get(), timeout=1.0)
            await session.send(video_data)
        except asyncio.TimeoutError:
            continue
        except Exception as e:
            print(f"‚ùå Error sending video: {e}")
            break

async def receive_responses(session):
    """Receive and handle responses from Gemini"""
    global conversation_active, audio_manager
    
    while conversation_active:
        try:
            async for response in session.receive():
                if response.data:
                    audio_manager.add_audio(response.data)
                elif response.tool_call:
                    # Handle tool calls
                    tool_call = response.tool_call
                    if tool_call.function_calls:
                        for func_call in tool_call.function_calls:
                            if func_call.name == "get_recipe":
                                query = func_call.args.get("query", "")
                                result = get_recipe(query)
                                await session.send({
                                    "tool_response": {
                                        "function_responses": [{
                                            "name": "get_recipe",
                                            "response": {"result": result}
                                        }]
                                    }
                                })
        except Exception as e:
            print(f"‚ùå Error receiving responses: {e}")
            break

def start_conversation():
    """Start the conversation"""
    global conversation_active
    
    if conversation_active:
        return "Already running", gr.update(interactive=False), gr.update(interactive=True)
    
    conversation_active = True
    
    # Start conversation in a separate thread
    def run_conversation():
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        try:
            loop.run_until_complete(conversation_loop())
        finally:
            loop.close()
    
    thread = threading.Thread(target=run_conversation, daemon=True)
    thread.start()
    
    return "üöÄ Conversation started! Talk to Nora!", gr.update(interactive=False), gr.update(interactive=True)

def stop_conversation():
    """Stop the conversation"""
    global conversation_active, audio_manager, cap
    
    conversation_active = False
    
    if audio_manager:
        audio_manager.interrupt()
        audio_manager.close_streams()
    
    if cap:
        cap.release()
    
    return "üõë Conversation stopped", gr.update(interactive=True), gr.update(interactive=False)

def get_camera_feed():
    """Get camera feed for display"""
    global cap
    
    if cap is None or not cap.isOpened():
        # Return a black frame if no camera
        return np.zeros((480, 640, 3), dtype=np.uint8)
    
    ret, frame = cap.read()
    if ret:
        return cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    else:
        return np.zeros((480, 640, 3), dtype=np.uint8)

# Create the interface
def create_interface():
    with gr.Blocks(
        title="Nora - AI Grocery Assistant",
        theme=gr.themes.Soft(),
        css="""
        .main-container { 
            height: 100vh; 
            display: flex; 
            flex-direction: column; 
            margin: 0; 
            padding: 0; 
        }
        .header { 
            text-align: center; 
            padding: 20px; 
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            margin: 0;
        }
        .camera-container { 
            flex: 1; 
            display: flex; 
            justify-content: center; 
            align-items: center; 
            background: #000;
            margin: 0;
        }
        .controls { 
            position: fixed; 
            bottom: 30px; 
            left: 50%; 
            transform: translateX(-50%); 
            z-index: 1000;
        }
        .status-overlay {
            position: fixed;
            top: 100px;
            left: 50%;
            transform: translateX(-50%);
            background: rgba(0,0,0,0.7);
            color: white;
            padding: 10px 20px;
            border-radius: 20px;
            z-index: 1000;
        }
        """
    ) as interface:
        
        # Header
        gr.HTML("""
        <div class="header">
            <h1>Nora - Your AI Grocery Assistant</h1>
        </div>
        """)
        
        # Camera feed
        camera_feed = gr.Image(
            value=get_camera_feed,
            streaming=True,
            every=0.1,
            height=600,
            width=800,
            show_label=False,
            show_download_button=False,
            container=False
        )
        
        # Status display
        status = gr.Textbox(
            value="Ready to start conversation",
            show_label=False,
            interactive=False,
            elem_classes="status-overlay"
        )
        
        # Control buttons
        with gr.Row(elem_classes="controls"):
            start_btn = gr.Button("üöÄ Start Conversation", variant="primary", size="lg", scale=1)
            stop_btn = gr.Button("üõë Stop Conversation", variant="secondary", size="lg", scale=1, interactive=False)
        
        # Event handlers
        start_btn.click(
            fn=start_conversation,
            outputs=[status, start_btn, stop_btn]
        )
        
        stop_btn.click(
            fn=stop_conversation,
            outputs=[status, start_btn, stop_btn]
        )

    return interface

if __name__ == "__main__":
    # Check for required environment variables
    if not os.getenv("GEMINI_API_KEY"):
        print("‚ùå Error: GEMINI_API_KEY environment variable not set")
        print("Please set your Gemini API key in a .env file or environment variable")
        exit(1)
    
    print("üöÄ Starting Nora - AI Grocery Assistant")
    
    # Create and launch the interface
    interface = create_interface()
    interface.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=False,
        inbrowser=True
    )

    # Cleanup
    if audio_manager:
        audio_manager.interrupt()
        audio_manager.close_streams()
    
    if cap:
        cap.release()